{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNnrsEM/QYIGSKB0sDDXaPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tocom242242/notebooks/blob/master/llm/nanogpt_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k77qI419xKsn",
        "outputId": "458fb03c-9448-4f02-f98a-cb60960d2c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/nanoGPT.git\n",
        "%cd nanoGPT\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1iUqF6FxPD7",
        "outputId": "996dfc35-0afc-4506-9089-9c2301eadb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 682, done.\u001b[K\n",
            "remote: Total 682 (delta 0), reused 0 (delta 0), pack-reused 682 (from 1)\u001b[K\n",
            "Receiving objects: 100% (682/682), 952.47 KiB | 4.11 MiB/s, done.\n",
            "Resolving deltas: 100% (385/385), done.\n",
            "/content/nanoGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data/shakespeare_char/prepare.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeWAJ-AiyK9W",
        "outputId": "c96fae6e-9c35-41a8-cc25-26bd4879cad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py config/train_shakespeare_char.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7A_MYQ8yOKQ",
        "outputId": "8c09b89e-43cc-483b-dbcf-e61582dd4c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_shakespeare_char.py:\n",
            "# train a miniature character-level shakespeare model\n",
            "# good for debugging and playing on macbooks and such\n",
            "\n",
            "out_dir = 'out-shakespeare-char'\n",
            "eval_interval = 250 # keep frequent because we'll overfit\n",
            "eval_iters = 200\n",
            "log_interval = 10 # don't print too too often\n",
            "\n",
            "# we expect to overfit on this small dataset, so only save when val improves\n",
            "always_save_checkpoint = False\n",
            "\n",
            "wandb_log = False # override via command line if you like\n",
            "wandb_project = 'shakespeare-char'\n",
            "wandb_run_name = 'mini-gpt'\n",
            "\n",
            "dataset = 'shakespeare_char'\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "\n",
            "# baby GPT model :)\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 384\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 5000\n",
            "lr_decay_iters = 5000 # make equal to max_iters usually\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "\n",
            "# on macbook also add\n",
            "# device = 'cpu'  # run on cpu only\n",
            "# compile = False # do not torch compile the model\n",
            "\n",
            "tokens per iteration will be: 16,384\n",
            "found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 10.65M\n",
            "num decayed parameter tensors: 26, with 10,740,096 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 4.2874, val loss 4.2823\n",
            "iter 0: loss 4.2653, time 44245.07ms, mfu -100.00%\n",
            "iter 10: loss 3.2457, time 12.39ms, mfu 30.07%\n",
            "iter 20: loss 2.7915, time 12.49ms, mfu 30.04%\n",
            "iter 30: loss 2.6355, time 12.48ms, mfu 30.03%\n",
            "iter 40: loss 2.5778, time 12.25ms, mfu 30.07%\n",
            "iter 50: loss 2.5275, time 12.18ms, mfu 30.12%\n",
            "iter 60: loss 2.5197, time 12.24ms, mfu 30.15%\n",
            "iter 70: loss 2.4955, time 12.90ms, mfu 30.03%\n",
            "iter 80: loss 2.4976, time 12.16ms, mfu 30.09%\n",
            "iter 90: loss 2.4678, time 12.23ms, mfu 30.13%\n",
            "iter 100: loss 2.4607, time 12.36ms, mfu 30.13%\n",
            "iter 110: loss 2.4545, time 12.34ms, mfu 30.14%\n",
            "iter 120: loss 2.4286, time 12.27ms, mfu 30.16%\n",
            "iter 130: loss 2.4149, time 12.27ms, mfu 30.18%\n",
            "iter 140: loss 2.4315, time 12.34ms, mfu 30.18%\n",
            "iter 150: loss 2.4223, time 12.30ms, mfu 30.19%\n",
            "iter 160: loss 2.3755, time 12.23ms, mfu 30.22%\n",
            "iter 170: loss 2.3516, time 12.26ms, mfu 30.24%\n",
            "iter 180: loss 2.3179, time 12.26ms, mfu 30.25%\n",
            "iter 190: loss 2.2614, time 12.29ms, mfu 30.26%\n",
            "iter 200: loss 2.2110, time 12.19ms, mfu 30.29%\n",
            "iter 210: loss 2.1458, time 12.52ms, mfu 30.24%\n",
            "iter 220: loss 2.1454, time 12.77ms, mfu 30.13%\n",
            "iter 230: loss 2.0692, time 12.55ms, mfu 30.09%\n",
            "iter 240: loss 2.0786, time 12.48ms, mfu 30.06%\n",
            "step 250: train loss 1.9655, val loss 2.0634\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 250: loss 2.0325, time 2803.71ms, mfu 27.07%\n",
            "iter 260: loss 1.9760, time 12.67ms, mfu 27.30%\n",
            "iter 270: loss 1.9862, time 12.45ms, mfu 27.57%\n",
            "iter 280: loss 1.9828, time 12.84ms, mfu 27.71%\n",
            "iter 290: loss 1.9187, time 12.56ms, mfu 27.91%\n",
            "iter 300: loss 1.9054, time 12.21ms, mfu 28.17%\n",
            "iter 310: loss 1.8728, time 12.21ms, mfu 28.40%\n",
            "iter 320: loss 1.8535, time 12.12ms, mfu 28.64%\n",
            "iter 330: loss 1.8227, time 12.43ms, mfu 28.77%\n",
            "iter 340: loss 1.7874, time 12.59ms, mfu 28.85%\n",
            "iter 350: loss 1.8248, time 12.64ms, mfu 28.92%\n",
            "iter 360: loss 1.7725, time 12.72ms, mfu 28.95%\n",
            "iter 370: loss 1.7516, time 13.04ms, mfu 28.92%\n",
            "iter 380: loss 1.7337, time 16.44ms, mfu 28.29%\n",
            "iter 390: loss 1.7395, time 12.48ms, mfu 28.45%\n",
            "iter 400: loss 1.7687, time 12.64ms, mfu 28.55%\n",
            "iter 410: loss 1.7018, time 12.31ms, mfu 28.72%\n",
            "iter 420: loss 1.7152, time 12.47ms, mfu 28.84%\n",
            "iter 430: loss 1.6890, time 12.43ms, mfu 28.95%\n",
            "iter 440: loss 1.6548, time 12.38ms, mfu 29.07%\n",
            "iter 450: loss 1.6514, time 12.56ms, mfu 29.13%\n",
            "iter 460: loss 1.6011, time 12.37ms, mfu 29.23%\n",
            "iter 470: loss 1.6507, time 12.36ms, mfu 29.32%\n",
            "iter 480: loss 1.6270, time 12.48ms, mfu 29.37%\n",
            "iter 490: loss 1.6049, time 12.40ms, mfu 29.44%\n",
            "step 500: train loss 1.5226, val loss 1.7250\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 500: loss 1.6033, time 2893.81ms, mfu 26.51%\n",
            "iter 510: loss 1.6184, time 12.52ms, mfu 26.83%\n",
            "iter 520: loss 1.5948, time 12.58ms, mfu 27.11%\n",
            "iter 530: loss 1.5647, time 12.57ms, mfu 27.37%\n",
            "iter 540: loss 1.6233, time 12.48ms, mfu 27.62%\n",
            "iter 550: loss 1.5592, time 12.51ms, mfu 27.83%\n",
            "iter 560: loss 1.5670, time 12.52ms, mfu 28.03%\n",
            "iter 570: loss 1.5709, time 13.01ms, mfu 28.09%\n",
            "iter 580: loss 1.5352, time 12.48ms, mfu 28.26%\n",
            "iter 590: loss 1.4982, time 12.46ms, mfu 28.43%\n",
            "iter 600: loss 1.5120, time 12.52ms, mfu 28.56%\n",
            "iter 610: loss 1.5492, time 12.53ms, mfu 28.68%\n",
            "iter 620: loss 1.5316, time 12.77ms, mfu 28.73%\n",
            "iter 630: loss 1.5136, time 12.54ms, mfu 28.83%\n",
            "iter 640: loss 1.4670, time 12.56ms, mfu 28.91%\n",
            "iter 650: loss 1.5030, time 12.39ms, mfu 29.03%\n",
            "iter 660: loss 1.5102, time 12.55ms, mfu 29.10%\n",
            "iter 670: loss 1.4422, time 12.34ms, mfu 29.21%\n",
            "iter 680: loss 1.5109, time 12.41ms, mfu 29.29%\n",
            "iter 690: loss 1.4648, time 12.39ms, mfu 29.37%\n",
            "iter 700: loss 1.4897, time 15.29ms, mfu 28.87%\n",
            "iter 710: loss 1.4599, time 12.30ms, mfu 29.01%\n",
            "iter 720: loss 1.4446, time 12.95ms, mfu 28.99%\n",
            "iter 730: loss 1.4303, time 12.72ms, mfu 29.02%\n",
            "iter 740: loss 1.4321, time 12.65ms, mfu 29.06%\n",
            "step 750: train loss 1.3687, val loss 1.5927\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 750: loss 1.4300, time 2911.04ms, mfu 26.17%\n",
            "iter 760: loss 1.4493, time 12.73ms, mfu 26.48%\n",
            "iter 770: loss 1.4276, time 12.67ms, mfu 26.77%\n",
            "iter 780: loss 1.4181, time 12.84ms, mfu 26.99%\n",
            "iter 790: loss 1.4216, time 12.72ms, mfu 27.22%\n",
            "iter 800: loss 1.4308, time 12.40ms, mfu 27.51%\n",
            "iter 810: loss 1.4128, time 13.07ms, mfu 27.61%\n",
            "iter 820: loss 1.4108, time 16.55ms, mfu 27.10%\n",
            "iter 830: loss 1.3953, time 14.08ms, mfu 27.04%\n",
            "iter 840: loss 1.4047, time 13.52ms, mfu 27.09%\n",
            "iter 850: loss 1.3934, time 13.28ms, mfu 27.19%\n",
            "iter 860: loss 1.4023, time 12.43ms, mfu 27.46%\n",
            "iter 870: loss 1.4012, time 12.59ms, mfu 27.68%\n",
            "iter 880: loss 1.3770, time 12.31ms, mfu 27.94%\n",
            "iter 890: loss 1.3909, time 12.39ms, mfu 28.15%\n",
            "iter 900: loss 1.3725, time 12.23ms, mfu 28.38%\n",
            "iter 910: loss 1.3234, time 12.58ms, mfu 28.51%\n",
            "iter 920: loss 1.3688, time 12.59ms, mfu 28.62%\n",
            "iter 930: loss 1.3622, time 12.40ms, mfu 28.76%\n",
            "iter 940: loss 1.3561, time 12.26ms, mfu 28.92%\n",
            "iter 950: loss 1.3597, time 12.53ms, mfu 29.00%\n",
            "iter 960: loss 1.3711, time 12.27ms, mfu 29.14%\n",
            "iter 970: loss 1.3593, time 12.38ms, mfu 29.24%\n",
            "iter 980: loss 1.3582, time 12.42ms, mfu 29.31%\n",
            "iter 990: loss 1.3517, time 12.34ms, mfu 29.40%\n",
            "step 1000: train loss 1.2775, val loss 1.5296\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 1000: loss 1.3379, time 2906.43ms, mfu 26.48%\n",
            "iter 1010: loss 1.3506, time 12.37ms, mfu 26.84%\n",
            "iter 1020: loss 1.3136, time 12.39ms, mfu 27.16%\n",
            "iter 1030: loss 1.3411, time 12.19ms, mfu 27.50%\n",
            "iter 1040: loss 1.3632, time 16.74ms, mfu 26.98%\n",
            "iter 1050: loss 1.2985, time 12.69ms, mfu 27.22%\n",
            "iter 1060: loss 1.3401, time 12.73ms, mfu 27.42%\n",
            "iter 1070: loss 1.3429, time 12.35ms, mfu 27.70%\n",
            "iter 1080: loss 1.3435, time 12.26ms, mfu 27.97%\n",
            "iter 1090: loss 1.3563, time 12.85ms, mfu 28.07%\n",
            "iter 1100: loss 1.3291, time 12.37ms, mfu 28.28%\n",
            "iter 1110: loss 1.3046, time 12.35ms, mfu 28.47%\n",
            "iter 1120: loss 1.3077, time 12.65ms, mfu 28.56%\n",
            "iter 1130: loss 1.3002, time 12.99ms, mfu 28.58%\n",
            "iter 1140: loss 1.3041, time 12.27ms, mfu 28.76%\n",
            "iter 1150: loss 1.3084, time 12.25ms, mfu 28.92%\n",
            "iter 1160: loss 1.3339, time 12.35ms, mfu 29.05%\n",
            "iter 1170: loss 1.3065, time 12.68ms, mfu 29.08%\n",
            "iter 1180: loss 1.3241, time 12.68ms, mfu 29.11%\n",
            "iter 1190: loss 1.2657, time 12.76ms, mfu 29.12%\n",
            "iter 1200: loss 1.2891, time 13.48ms, mfu 28.97%\n",
            "iter 1210: loss 1.2652, time 12.40ms, mfu 29.08%\n",
            "iter 1220: loss 1.3130, time 12.18ms, mfu 29.23%\n",
            "iter 1230: loss 1.3013, time 12.49ms, mfu 29.29%\n",
            "iter 1240: loss 1.3035, time 12.45ms, mfu 29.35%\n",
            "step 1250: train loss 1.2070, val loss 1.4964\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 1250: loss 1.2719, time 2921.87ms, mfu 26.43%\n",
            "iter 1260: loss 1.2841, time 12.63ms, mfu 26.74%\n",
            "iter 1270: loss 1.2702, time 15.59ms, mfu 26.45%\n",
            "iter 1280: loss 1.2607, time 15.80ms, mfu 26.17%\n",
            "iter 1290: loss 1.2849, time 12.42ms, mfu 26.55%\n",
            "iter 1300: loss 1.3059, time 13.31ms, mfu 26.70%\n",
            "iter 1310: loss 1.2390, time 12.56ms, mfu 26.99%\n",
            "iter 1320: loss 1.3076, time 13.02ms, mfu 27.16%\n",
            "iter 1330: loss 1.2651, time 12.43ms, mfu 27.44%\n",
            "iter 1340: loss 1.3066, time 12.48ms, mfu 27.68%\n",
            "iter 1350: loss 1.2578, time 12.34ms, mfu 27.93%\n",
            "iter 1360: loss 1.2846, time 15.35ms, mfu 27.57%\n",
            "iter 1370: loss 1.2622, time 12.75ms, mfu 27.73%\n",
            "iter 1380: loss 1.2670, time 12.30ms, mfu 27.99%\n",
            "iter 1390: loss 1.2509, time 12.47ms, mfu 28.18%\n",
            "iter 1400: loss 1.2608, time 12.42ms, mfu 28.36%\n",
            "iter 1410: loss 1.2514, time 12.19ms, mfu 28.58%\n",
            "iter 1420: loss 1.2754, time 12.41ms, mfu 28.73%\n",
            "iter 1430: loss 1.2480, time 12.30ms, mfu 28.88%\n",
            "iter 1440: loss 1.2546, time 12.24ms, mfu 29.04%\n",
            "iter 1450: loss 1.2320, time 12.36ms, mfu 29.15%\n",
            "iter 1460: loss 1.2498, time 12.22ms, mfu 29.29%\n",
            "iter 1470: loss 1.2250, time 12.21ms, mfu 29.41%\n",
            "iter 1480: loss 1.2137, time 12.24ms, mfu 29.51%\n",
            "iter 1490: loss 1.2395, time 12.43ms, mfu 29.56%\n",
            "step 1500: train loss 1.1569, val loss 1.4763\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 1500: loss 1.1906, time 2879.84ms, mfu 26.62%\n",
            "iter 1510: loss 1.2432, time 12.27ms, mfu 26.99%\n",
            "iter 1520: loss 1.2324, time 12.30ms, mfu 27.32%\n",
            "iter 1530: loss 1.2620, time 12.24ms, mfu 27.63%\n",
            "iter 1540: loss 1.1986, time 12.36ms, mfu 27.88%\n",
            "iter 1550: loss 1.2350, time 12.22ms, mfu 28.14%\n",
            "iter 1560: loss 1.2138, time 12.21ms, mfu 28.38%\n",
            "iter 1570: loss 1.2415, time 12.24ms, mfu 28.59%\n",
            "iter 1580: loss 1.2153, time 12.22ms, mfu 28.78%\n",
            "iter 1590: loss 1.1956, time 12.72ms, mfu 28.83%\n",
            "iter 1600: loss 1.1995, time 12.51ms, mfu 28.92%\n",
            "iter 1610: loss 1.2386, time 12.29ms, mfu 29.06%\n",
            "iter 1620: loss 1.1859, time 12.24ms, mfu 29.20%\n",
            "iter 1630: loss 1.2138, time 12.32ms, mfu 29.31%\n",
            "iter 1640: loss 1.2035, time 12.18ms, mfu 29.43%\n",
            "iter 1650: loss 1.1826, time 13.67ms, mfu 29.22%\n",
            "iter 1660: loss 1.2157, time 12.20ms, mfu 29.35%\n",
            "iter 1670: loss 1.1984, time 12.26ms, mfu 29.45%\n",
            "iter 1680: loss 1.2028, time 12.28ms, mfu 29.54%\n",
            "iter 1690: loss 1.2024, time 12.45ms, mfu 29.58%\n",
            "iter 1700: loss 1.1863, time 12.38ms, mfu 29.63%\n",
            "iter 1710: loss 1.1812, time 12.39ms, mfu 29.68%\n",
            "iter 1720: loss 1.1859, time 12.42ms, mfu 29.71%\n",
            "iter 1730: loss 1.2068, time 12.45ms, mfu 29.73%\n",
            "iter 1740: loss 1.1711, time 12.10ms, mfu 29.84%\n",
            "step 1750: train loss 1.1100, val loss 1.4687\n",
            "saving checkpoint to out-shakespeare-char\n",
            "iter 1750: loss 1.1847, time 2910.93ms, mfu 26.87%\n",
            "iter 1760: loss 1.1899, time 13.60ms, mfu 26.92%\n",
            "iter 1770: loss 1.2008, time 12.58ms, mfu 27.19%\n",
            "iter 1780: loss 1.2004, time 12.95ms, mfu 27.35%\n",
            "iter 1790: loss 1.1950, time 12.77ms, mfu 27.53%\n",
            "iter 1800: loss 1.1842, time 12.39ms, mfu 27.79%\n",
            "iter 1810: loss 1.1644, time 12.30ms, mfu 28.04%\n",
            "iter 1820: loss 1.1684, time 12.31ms, mfu 28.26%\n",
            "iter 1830: loss 1.1741, time 12.56ms, mfu 28.40%\n",
            "iter 1840: loss 1.1647, time 12.30ms, mfu 28.59%\n",
            "iter 1850: loss 1.1591, time 12.45ms, mfu 28.72%\n",
            "iter 1860: loss 1.1723, time 12.37ms, mfu 28.86%\n",
            "iter 1870: loss 1.1396, time 12.42ms, mfu 28.98%\n",
            "iter 1880: loss 1.1833, time 12.30ms, mfu 29.11%\n",
            "iter 1890: loss 1.1805, time 12.26ms, mfu 29.24%\n",
            "iter 1900: loss 1.1305, time 12.24ms, mfu 29.36%\n",
            "iter 1910: loss 1.1748, time 12.28ms, mfu 29.46%\n",
            "iter 1920: loss 1.1707, time 12.23ms, mfu 29.56%\n",
            "iter 1930: loss 1.1456, time 12.20ms, mfu 29.66%\n",
            "iter 1940: loss 1.1299, time 12.35ms, mfu 29.71%\n",
            "iter 1950: loss 1.1420, time 12.31ms, mfu 29.77%\n",
            "iter 1960: loss 1.1479, time 12.25ms, mfu 29.83%\n",
            "iter 1970: loss 1.1478, time 13.72ms, mfu 29.56%\n",
            "iter 1980: loss 1.1594, time 12.26ms, mfu 29.65%\n",
            "iter 1990: loss 1.1543, time 12.33ms, mfu 29.70%\n",
            "step 2000: train loss 1.0621, val loss 1.4729\n",
            "iter 2000: loss 1.1303, time 2617.47ms, mfu 26.75%\n",
            "iter 2010: loss 1.1338, time 12.62ms, mfu 27.02%\n",
            "iter 2020: loss 1.1259, time 12.29ms, mfu 27.35%\n",
            "iter 2030: loss 1.1562, time 12.20ms, mfu 27.67%\n",
            "iter 2040: loss 1.1456, time 12.23ms, mfu 27.95%\n",
            "iter 2050: loss 1.1203, time 13.65ms, mfu 27.89%\n",
            "iter 2060: loss 1.1086, time 12.44ms, mfu 28.09%\n",
            "iter 2070: loss 1.1252, time 12.50ms, mfu 28.27%\n",
            "iter 2080: loss 1.1210, time 12.59ms, mfu 28.40%\n",
            "iter 2090: loss 1.1292, time 12.36ms, mfu 28.57%\n",
            "iter 2100: loss 1.1341, time 12.90ms, mfu 28.61%\n",
            "iter 2110: loss 1.1288, time 12.57ms, mfu 28.71%\n",
            "iter 2120: loss 1.1334, time 13.96ms, mfu 28.51%\n",
            "iter 2130: loss 1.1397, time 12.23ms, mfu 28.70%\n",
            "iter 2140: loss 1.1405, time 12.25ms, mfu 28.88%\n",
            "iter 2150: loss 1.1253, time 12.15ms, mfu 29.05%\n",
            "iter 2160: loss 1.1432, time 12.45ms, mfu 29.14%\n",
            "iter 2170: loss 1.1374, time 12.22ms, mfu 29.28%\n",
            "iter 2180: loss 1.1163, time 12.17ms, mfu 29.41%\n",
            "iter 2190: loss 1.1152, time 12.15ms, mfu 29.54%\n",
            "iter 2200: loss 1.1279, time 12.29ms, mfu 29.62%\n",
            "iter 2210: loss 1.1177, time 12.21ms, mfu 29.71%\n",
            "iter 2220: loss 1.1264, time 12.22ms, mfu 29.78%\n",
            "iter 2230: loss 1.1260, time 13.56ms, mfu 29.55%\n",
            "iter 2240: loss 1.1247, time 12.38ms, mfu 29.61%\n",
            "step 2250: train loss 1.0117, val loss 1.4770\n",
            "iter 2250: loss 1.1132, time 2725.23ms, mfu 26.66%\n",
            "iter 2260: loss 1.1040, time 12.65ms, mfu 26.94%\n",
            "iter 2270: loss 1.1290, time 12.46ms, mfu 27.24%\n",
            "iter 2280: loss 1.1005, time 12.38ms, mfu 27.52%\n",
            "iter 2290: loss 1.1432, time 12.47ms, mfu 27.76%\n",
            "iter 2300: loss 1.1247, time 12.60ms, mfu 27.94%\n",
            "iter 2310: loss 1.0986, time 12.43ms, mfu 28.15%\n",
            "iter 2320: loss 1.0976, time 12.46ms, mfu 28.32%\n",
            "iter 2330: loss 1.1007, time 12.65ms, mfu 28.44%\n",
            "iter 2340: loss 1.1192, time 12.21ms, mfu 28.64%\n",
            "iter 2350: loss 1.1147, time 13.01ms, mfu 28.64%\n",
            "iter 2360: loss 1.1085, time 12.84ms, mfu 28.68%\n",
            "iter 2370: loss 1.0933, time 12.42ms, mfu 28.81%\n",
            "iter 2380: loss 1.0839, time 12.43ms, mfu 28.93%\n",
            "iter 2390: loss 1.0822, time 12.52ms, mfu 29.01%\n",
            "iter 2400: loss 1.0859, time 12.60ms, mfu 29.07%\n",
            "iter 2410: loss 1.0688, time 12.29ms, mfu 29.19%\n",
            "iter 2420: loss 1.0820, time 12.30ms, mfu 29.30%\n",
            "iter 2430: loss 1.0593, time 12.60ms, mfu 29.33%\n",
            "iter 2440: loss 1.0603, time 13.40ms, mfu 29.18%\n",
            "iter 2450: loss 1.0768, time 13.09ms, mfu 29.11%\n",
            "iter 2460: loss 1.0889, time 12.43ms, mfu 29.19%\n",
            "iter 2470: loss 1.0963, time 12.41ms, mfu 29.28%\n",
            "iter 2480: loss 1.0926, time 12.37ms, mfu 29.36%\n",
            "iter 2490: loss 1.0574, time 12.49ms, mfu 29.41%\n",
            "step 2500: train loss 0.9635, val loss 1.4892\n",
            "iter 2500: loss 1.0857, time 2630.82ms, mfu 26.48%\n",
            "iter 2510: loss 1.0751, time 12.38ms, mfu 26.84%\n",
            "iter 2520: loss 1.0426, time 12.43ms, mfu 27.16%\n",
            "iter 2530: loss 1.0554, time 12.38ms, mfu 27.45%\n",
            "iter 2540: loss 1.0572, time 12.56ms, mfu 27.67%\n",
            "iter 2550: loss 1.0692, time 12.28ms, mfu 27.94%\n",
            "iter 2560: loss 1.0649, time 13.39ms, mfu 27.93%\n",
            "iter 2570: loss 1.0737, time 14.19ms, mfu 27.76%\n",
            "iter 2580: loss 1.0858, time 12.33ms, mfu 28.01%\n",
            "iter 2590: loss 1.0578, time 12.20ms, mfu 28.27%\n",
            "iter 2600: loss 1.0739, time 12.41ms, mfu 28.44%\n",
            "iter 2610: loss 1.0569, time 12.20ms, mfu 28.65%\n",
            "iter 2620: loss 1.0512, time 12.63ms, mfu 28.74%\n",
            "iter 2630: loss 1.0284, time 12.21ms, mfu 28.92%\n",
            "iter 2640: loss 1.0440, time 12.49ms, mfu 29.01%\n",
            "iter 2650: loss 1.0680, time 12.16ms, mfu 29.17%\n",
            "iter 2660: loss 1.0423, time 12.21ms, mfu 29.30%\n",
            "iter 2670: loss 1.0230, time 12.31ms, mfu 29.40%\n",
            "iter 2680: loss 1.0554, time 13.28ms, mfu 29.27%\n",
            "iter 2690: loss 1.0533, time 12.20ms, mfu 29.39%\n",
            "iter 2700: loss 1.0250, time 14.15ms, mfu 29.09%\n",
            "iter 2710: loss 1.0479, time 12.40ms, mfu 29.19%\n",
            "iter 2720: loss 1.0435, time 12.18ms, mfu 29.33%\n",
            "iter 2730: loss 1.0656, time 12.30ms, mfu 29.42%\n",
            "iter 2740: loss 1.0315, time 12.23ms, mfu 29.53%\n",
            "step 2750: train loss 0.9179, val loss 1.5077\n",
            "iter 2750: loss 1.0383, time 2622.86ms, mfu 26.59%\n",
            "iter 2760: loss 1.0365, time 12.72ms, mfu 26.86%\n",
            "iter 2770: loss 1.0252, time 12.26ms, mfu 27.21%\n",
            "iter 2780: loss 1.0226, time 12.34ms, mfu 27.51%\n",
            "iter 2790: loss 1.0435, time 12.37ms, mfu 27.77%\n",
            "iter 2800: loss 1.0128, time 12.33ms, mfu 28.02%\n",
            "iter 2810: loss 1.0449, time 12.39ms, mfu 28.23%\n",
            "iter 2820: loss 1.0336, time 13.09ms, mfu 28.25%\n",
            "iter 2830: loss 1.0444, time 12.73ms, mfu 28.35%\n",
            "iter 2840: loss 0.9986, time 12.66ms, mfu 28.46%\n",
            "iter 2850: loss 1.0242, time 12.51ms, mfu 28.59%\n",
            "iter 2860: loss 1.0196, time 12.42ms, mfu 28.73%\n",
            "iter 2870: loss 1.0037, time 12.49ms, mfu 28.84%\n",
            "iter 2880: loss 1.0413, time 12.52ms, mfu 28.93%\n",
            "iter 2890: loss 1.0123, time 12.48ms, mfu 29.03%\n",
            "iter 2900: loss 0.9942, time 12.52ms, mfu 29.10%\n",
            "iter 2910: loss 1.0421, time 12.24ms, mfu 29.24%\n",
            "iter 2920: loss 1.0145, time 12.38ms, mfu 29.32%\n",
            "iter 2930: loss 0.9963, time 12.23ms, mfu 29.44%\n",
            "iter 2940: loss 0.9961, time 12.82ms, mfu 29.40%\n",
            "iter 2950: loss 1.0240, time 12.20ms, mfu 29.51%\n",
            "iter 2960: loss 1.0048, time 12.13ms, mfu 29.63%\n",
            "iter 2970: loss 0.9867, time 12.87ms, mfu 29.57%\n",
            "iter 2980: loss 0.9998, time 14.20ms, mfu 29.23%\n",
            "iter 2990: loss 0.9871, time 12.18ms, mfu 29.37%\n",
            "step 3000: train loss 0.8697, val loss 1.5266\n",
            "iter 3000: loss 0.9854, time 2611.14ms, mfu 26.45%\n",
            "iter 3010: loss 0.9922, time 12.16ms, mfu 26.87%\n",
            "iter 3020: loss 1.0025, time 12.13ms, mfu 27.25%\n",
            "iter 3030: loss 1.0075, time 12.18ms, mfu 27.59%\n",
            "iter 3040: loss 1.0225, time 12.15ms, mfu 27.90%\n",
            "iter 3050: loss 0.9786, time 12.79ms, mfu 28.02%\n",
            "iter 3060: loss 1.0031, time 12.46ms, mfu 28.21%\n",
            "iter 3070: loss 1.0240, time 13.08ms, mfu 28.24%\n",
            "iter 3080: loss 0.9969, time 12.11ms, mfu 28.49%\n",
            "iter 3090: loss 0.9862, time 12.89ms, mfu 28.53%\n",
            "iter 3100: loss 0.9999, time 13.48ms, mfu 28.44%\n",
            "iter 3110: loss 0.9724, time 12.14ms, mfu 28.67%\n",
            "iter 3120: loss 0.9915, time 12.12ms, mfu 28.87%\n",
            "iter 3130: loss 0.9717, time 12.19ms, mfu 29.04%\n",
            "iter 3140: loss 0.9823, time 12.14ms, mfu 29.21%\n",
            "iter 3150: loss 1.0040, time 13.17ms, mfu 29.12%\n",
            "iter 3160: loss 1.0066, time 12.09ms, mfu 29.29%\n",
            "iter 3170: loss 0.9637, time 12.37ms, mfu 29.37%\n",
            "iter 3180: loss 0.9703, time 12.14ms, mfu 29.50%\n",
            "iter 3190: loss 1.0032, time 12.09ms, mfu 29.63%\n",
            "iter 3200: loss 0.9648, time 12.68ms, mfu 29.61%\n",
            "iter 3210: loss 0.9678, time 12.17ms, mfu 29.71%\n",
            "iter 3220: loss 0.9611, time 12.08ms, mfu 29.82%\n",
            "iter 3230: loss 0.9552, time 12.13ms, mfu 29.91%\n",
            "iter 3240: loss 0.9609, time 13.53ms, mfu 29.67%\n",
            "step 3250: train loss 0.8269, val loss 1.5599\n",
            "iter 3250: loss 0.9768, time 2610.67ms, mfu 26.72%\n",
            "iter 3260: loss 0.9669, time 12.40ms, mfu 27.06%\n",
            "iter 3270: loss 0.9733, time 12.81ms, mfu 27.26%\n",
            "iter 3280: loss 0.9557, time 12.57ms, mfu 27.50%\n",
            "iter 3290: loss 0.9436, time 12.66ms, mfu 27.69%\n",
            "iter 3300: loss 0.9448, time 12.47ms, mfu 27.91%\n",
            "iter 3310: loss 0.9514, time 12.53ms, mfu 28.09%\n",
            "iter 3320: loss 0.9627, time 12.56ms, mfu 28.25%\n",
            "iter 3330: loss 0.9678, time 12.36ms, mfu 28.44%\n",
            "iter 3340: loss 0.9549, time 13.44ms, mfu 28.36%\n",
            "iter 3350: loss 0.9575, time 13.80ms, mfu 28.23%\n",
            "iter 3360: loss 0.9295, time 15.66ms, mfu 27.79%\n",
            "iter 3370: loss 0.9599, time 12.77ms, mfu 27.92%\n",
            "iter 3380: loss 0.9532, time 12.98ms, mfu 28.00%\n",
            "iter 3390: loss 0.9567, time 12.71ms, mfu 28.13%\n",
            "iter 3400: loss 0.9612, time 12.50ms, mfu 28.30%\n",
            "iter 3410: loss 0.9471, time 14.79ms, mfu 27.99%\n",
            "iter 3420: loss 0.9516, time 12.73ms, mfu 28.12%\n",
            "iter 3430: loss 0.9512, time 12.59ms, mfu 28.27%\n",
            "iter 3440: loss 0.9777, time 12.54ms, mfu 28.41%\n",
            "iter 3450: loss 0.9609, time 12.34ms, mfu 28.59%\n",
            "iter 3460: loss 0.9521, time 12.41ms, mfu 28.73%\n",
            "iter 3470: loss 0.9398, time 12.43ms, mfu 28.86%\n",
            "iter 3480: loss 0.9511, time 12.23ms, mfu 29.02%\n",
            "iter 3490: loss 0.9222, time 12.37ms, mfu 29.13%\n",
            "step 3500: train loss 0.7857, val loss 1.5677\n",
            "iter 3500: loss 0.9114, time 2622.82ms, mfu 26.23%\n",
            "iter 3510: loss 0.9103, time 12.21ms, mfu 26.66%\n",
            "iter 3520: loss 0.9226, time 12.47ms, mfu 26.98%\n",
            "iter 3530: loss 0.9507, time 12.85ms, mfu 27.18%\n",
            "iter 3540: loss 0.9339, time 12.60ms, mfu 27.42%\n",
            "iter 3550: loss 0.9227, time 12.52ms, mfu 27.65%\n",
            "iter 3560: loss 0.9580, time 12.97ms, mfu 27.76%\n",
            "iter 3570: loss 0.9397, time 12.43ms, mfu 27.98%\n",
            "iter 3580: loss 0.9329, time 12.31ms, mfu 28.21%\n",
            "iter 3590: loss 0.9278, time 12.38ms, mfu 28.40%\n",
            "iter 3600: loss 0.9301, time 12.24ms, mfu 28.61%\n",
            "iter 3610: loss 0.9178, time 12.26ms, mfu 28.78%\n",
            "iter 3620: loss 0.9082, time 12.37ms, mfu 28.92%\n",
            "iter 3630: loss 0.9281, time 12.31ms, mfu 29.05%\n",
            "iter 3640: loss 0.9169, time 12.29ms, mfu 29.18%\n",
            "iter 3650: loss 0.9154, time 12.46ms, mfu 29.25%\n",
            "iter 3660: loss 0.9384, time 12.23ms, mfu 29.37%\n",
            "iter 3670: loss 0.9552, time 12.27ms, mfu 29.47%\n",
            "iter 3680: loss 0.9068, time 12.91ms, mfu 29.41%\n",
            "iter 3690: loss 0.9398, time 13.22ms, mfu 29.29%\n",
            "iter 3700: loss 0.8715, time 12.15ms, mfu 29.43%\n",
            "iter 3710: loss 0.8874, time 12.44ms, mfu 29.48%\n",
            "iter 3720: loss 0.9100, time 12.54ms, mfu 29.50%\n",
            "iter 3730: loss 0.9077, time 12.18ms, mfu 29.61%\n",
            "iter 3740: loss 0.9113, time 12.99ms, mfu 29.52%\n",
            "step 3750: train loss 0.7459, val loss 1.5996\n",
            "iter 3750: loss 0.9023, time 2608.13ms, mfu 26.58%\n",
            "iter 3760: loss 0.9382, time 12.51ms, mfu 26.90%\n",
            "iter 3770: loss 0.9303, time 12.41ms, mfu 27.22%\n",
            "iter 3780: loss 0.9249, time 12.44ms, mfu 27.49%\n",
            "iter 3790: loss 0.9044, time 12.39ms, mfu 27.75%\n",
            "iter 3800: loss 0.9186, time 13.63ms, mfu 27.71%\n",
            "iter 3810: loss 0.9152, time 12.66ms, mfu 27.88%\n",
            "iter 3820: loss 0.8882, time 12.27ms, mfu 28.13%\n",
            "iter 3830: loss 0.9014, time 12.11ms, mfu 28.39%\n",
            "iter 3840: loss 0.8900, time 12.72ms, mfu 28.48%\n",
            "iter 3850: loss 0.8931, time 12.28ms, mfu 28.67%\n",
            "iter 3860: loss 0.8779, time 13.52ms, mfu 28.56%\n",
            "iter 3870: loss 0.8919, time 12.80ms, mfu 28.62%\n",
            "iter 3880: loss 0.8944, time 12.86ms, mfu 28.65%\n",
            "iter 3890: loss 0.8920, time 12.94ms, mfu 28.67%\n",
            "iter 3900: loss 0.9004, time 12.54ms, mfu 28.77%\n",
            "iter 3910: loss 0.8922, time 12.49ms, mfu 28.88%\n",
            "iter 3920: loss 0.8807, time 15.03ms, mfu 28.47%\n",
            "iter 3930: loss 0.8917, time 12.81ms, mfu 28.53%\n",
            "iter 3940: loss 0.8805, time 12.62ms, mfu 28.63%\n",
            "iter 3950: loss 0.8820, time 12.27ms, mfu 28.80%\n",
            "iter 3960: loss 0.9034, time 12.24ms, mfu 28.97%\n",
            "iter 3970: loss 0.8930, time 12.13ms, mfu 29.14%\n",
            "iter 3980: loss 0.8953, time 12.15ms, mfu 29.30%\n",
            "iter 3990: loss 0.8863, time 13.50ms, mfu 29.13%\n",
            "step 4000: train loss 0.7154, val loss 1.6255\n",
            "iter 4000: loss 0.8604, time 2619.92ms, mfu 26.23%\n",
            "iter 4010: loss 0.8845, time 12.18ms, mfu 26.66%\n",
            "iter 4020: loss 0.8884, time 12.60ms, mfu 26.96%\n",
            "iter 4030: loss 0.8878, time 12.53ms, mfu 27.23%\n",
            "iter 4040: loss 0.8837, time 12.40ms, mfu 27.52%\n",
            "iter 4050: loss 0.8754, time 12.35ms, mfu 27.78%\n",
            "iter 4060: loss 0.8746, time 12.20ms, mfu 28.06%\n",
            "iter 4070: loss 0.8652, time 12.18ms, mfu 28.31%\n",
            "iter 4080: loss 0.8896, time 12.13ms, mfu 28.55%\n",
            "iter 4090: loss 0.8573, time 12.08ms, mfu 28.78%\n",
            "iter 4100: loss 0.9022, time 12.46ms, mfu 28.89%\n",
            "iter 4110: loss 0.8757, time 12.14ms, mfu 29.08%\n",
            "iter 4120: loss 0.8729, time 12.39ms, mfu 29.18%\n",
            "iter 4130: loss 0.8650, time 12.23ms, mfu 29.31%\n",
            "iter 4140: loss 0.8831, time 12.37ms, mfu 29.39%\n",
            "iter 4150: loss 0.8706, time 12.29ms, mfu 29.48%\n",
            "iter 4160: loss 0.8553, time 12.18ms, mfu 29.59%\n",
            "iter 4170: loss 0.8611, time 12.17ms, mfu 29.69%\n",
            "iter 4180: loss 0.8719, time 12.66ms, mfu 29.67%\n",
            "iter 4190: loss 0.8760, time 12.28ms, mfu 29.74%\n",
            "iter 4200: loss 0.8617, time 12.27ms, mfu 29.80%\n",
            "iter 4210: loss 0.8696, time 12.19ms, mfu 29.88%\n",
            "iter 4220: loss 0.8694, time 12.31ms, mfu 29.92%\n",
            "iter 4230: loss 0.8852, time 12.24ms, mfu 29.97%\n",
            "iter 4240: loss 0.8717, time 12.16ms, mfu 30.04%\n",
            "step 4250: train loss 0.6831, val loss 1.6466\n",
            "iter 4250: loss 0.8733, time 2620.00ms, mfu 27.05%\n",
            "iter 4260: loss 0.8595, time 12.20ms, mfu 27.40%\n",
            "iter 4270: loss 0.8677, time 12.18ms, mfu 27.71%\n",
            "iter 4280: loss 0.8659, time 12.38ms, mfu 27.95%\n",
            "iter 4290: loss 0.8362, time 12.68ms, mfu 28.10%\n",
            "iter 4300: loss 0.8384, time 12.54ms, mfu 28.26%\n",
            "iter 4310: loss 0.8532, time 12.29ms, mfu 28.46%\n",
            "iter 4320: loss 0.8378, time 13.85ms, mfu 28.31%\n",
            "iter 4330: loss 0.8606, time 12.81ms, mfu 28.39%\n",
            "iter 4340: loss 0.8283, time 12.28ms, mfu 28.58%\n",
            "iter 4350: loss 0.8458, time 12.36ms, mfu 28.74%\n",
            "iter 4360: loss 0.8614, time 12.50ms, mfu 28.85%\n",
            "iter 4370: loss 0.8442, time 14.04ms, mfu 28.62%\n",
            "iter 4380: loss 0.8415, time 12.84ms, mfu 28.65%\n",
            "iter 4390: loss 0.8646, time 13.08ms, mfu 28.64%\n",
            "iter 4400: loss 0.8501, time 12.70ms, mfu 28.71%\n",
            "iter 4410: loss 0.8608, time 12.88ms, mfu 28.73%\n",
            "iter 4420: loss 0.8664, time 12.55ms, mfu 28.83%\n",
            "iter 4430: loss 0.8464, time 12.22ms, mfu 28.99%\n",
            "iter 4440: loss 0.8565, time 12.12ms, mfu 29.17%\n",
            "iter 4450: loss 0.8483, time 12.52ms, mfu 29.23%\n",
            "iter 4460: loss 0.8414, time 12.16ms, mfu 29.37%\n",
            "iter 4470: loss 0.8456, time 13.44ms, mfu 29.20%\n",
            "iter 4480: loss 0.8337, time 14.16ms, mfu 28.92%\n",
            "iter 4490: loss 0.8558, time 12.28ms, mfu 29.06%\n",
            "step 4500: train loss 0.6585, val loss 1.6703\n",
            "iter 4500: loss 0.8661, time 2622.59ms, mfu 26.17%\n",
            "iter 4510: loss 0.8573, time 12.93ms, mfu 26.43%\n",
            "iter 4520: loss 0.8367, time 12.24ms, mfu 26.83%\n",
            "iter 4530: loss 0.8524, time 12.15ms, mfu 27.22%\n",
            "iter 4540: loss 0.8465, time 12.15ms, mfu 27.56%\n",
            "iter 4550: loss 0.8754, time 12.15ms, mfu 27.87%\n",
            "iter 4560: loss 0.8444, time 12.15ms, mfu 28.15%\n",
            "iter 4570: loss 0.8511, time 12.09ms, mfu 28.42%\n",
            "iter 4580: loss 0.8668, time 12.14ms, mfu 28.65%\n",
            "iter 4590: loss 0.8579, time 12.31ms, mfu 28.81%\n",
            "iter 4600: loss 0.8238, time 12.10ms, mfu 29.01%\n",
            "iter 4610: loss 0.8742, time 12.22ms, mfu 29.16%\n",
            "iter 4620: loss 0.8375, time 12.49ms, mfu 29.22%\n",
            "iter 4630: loss 0.8256, time 12.18ms, mfu 29.36%\n",
            "iter 4640: loss 0.8402, time 12.39ms, mfu 29.43%\n",
            "iter 4650: loss 0.8606, time 12.32ms, mfu 29.51%\n",
            "iter 4660: loss 0.8539, time 12.24ms, mfu 29.61%\n",
            "iter 4670: loss 0.8418, time 12.20ms, mfu 29.70%\n",
            "iter 4680: loss 0.8568, time 12.22ms, mfu 29.78%\n",
            "iter 4690: loss 0.8583, time 12.44ms, mfu 29.80%\n",
            "iter 4700: loss 0.8289, time 12.15ms, mfu 29.88%\n",
            "iter 4710: loss 0.7969, time 12.19ms, mfu 29.95%\n",
            "iter 4720: loss 0.8292, time 12.24ms, mfu 30.00%\n",
            "iter 4730: loss 0.8299, time 12.35ms, mfu 30.02%\n",
            "iter 4740: loss 0.8323, time 12.32ms, mfu 30.04%\n",
            "step 4750: train loss 0.6409, val loss 1.6776\n",
            "iter 4750: loss 0.8136, time 2638.12ms, mfu 27.05%\n",
            "iter 4760: loss 0.8280, time 12.27ms, mfu 27.38%\n",
            "iter 4770: loss 0.8058, time 12.36ms, mfu 27.66%\n",
            "iter 4780: loss 0.8076, time 12.25ms, mfu 27.94%\n",
            "iter 4790: loss 0.8379, time 12.24ms, mfu 28.19%\n",
            "iter 4800: loss 0.8152, time 12.14ms, mfu 28.44%\n",
            "iter 4810: loss 0.8428, time 12.17ms, mfu 28.66%\n",
            "iter 4820: loss 0.8317, time 12.46ms, mfu 28.78%\n",
            "iter 4830: loss 0.8258, time 12.48ms, mfu 28.89%\n",
            "iter 4840: loss 0.8294, time 12.48ms, mfu 28.99%\n",
            "iter 4850: loss 0.8260, time 13.14ms, mfu 28.92%\n",
            "iter 4860: loss 0.8251, time 12.72ms, mfu 28.96%\n",
            "iter 4870: loss 0.8127, time 12.39ms, mfu 29.07%\n",
            "iter 4880: loss 0.8340, time 12.38ms, mfu 29.18%\n",
            "iter 4890: loss 0.8067, time 12.43ms, mfu 29.26%\n",
            "iter 4900: loss 0.8069, time 12.42ms, mfu 29.33%\n",
            "iter 4910: loss 0.8300, time 12.41ms, mfu 29.40%\n",
            "iter 4920: loss 0.8228, time 12.53ms, mfu 29.44%\n",
            "iter 4930: loss 0.8107, time 13.50ms, mfu 29.25%\n",
            "iter 4940: loss 0.7984, time 12.89ms, mfu 29.22%\n",
            "iter 4950: loss 0.8281, time 12.43ms, mfu 29.29%\n",
            "iter 4960: loss 0.8363, time 12.12ms, mfu 29.44%\n",
            "iter 4970: loss 0.7882, time 12.08ms, mfu 29.58%\n",
            "iter 4980: loss 0.8071, time 12.33ms, mfu 29.64%\n",
            "iter 4990: loss 0.8218, time 13.13ms, mfu 29.52%\n",
            "step 5000: train loss 0.6266, val loss 1.6986\n",
            "iter 5000: loss 0.8183, time 2628.29ms, mfu 26.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-42Zv72zzgV",
        "outputId": "07f2589b-8752-427a-ed8a-fd67c76920ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.17.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: xxhash, smmap, setproctitle, sentry-sdk, pyarrow, fsspec, docker-pycreds, dill, tiktoken, multiprocess, gitdb, gitpython, wandb, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 docker-pycreds-0.4.0 fsspec-2024.5.0 gitdb-4.0.11 gitpython-3.1.43 multiprocess-0.70.16 pyarrow-17.0.0 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.7.0 wandb-0.17.6 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample.py --out_dir=out-shakespeare-char --device=cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAQzupojy20D",
        "outputId": "8d619f21-d7e3-4958-d5dd-6f2454689988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: out_dir = out-shakespeare-char\n",
            "Overriding: device = cpu\n",
            "number of parameters: 10.65M\n",
            "Loading meta from data/shakespeare_char/meta.pkl...\n",
            "\n",
            "Believe the servant, pity the bastard;\n",
            "Enjoy to our bed, your face is a rude to see,\n",
            "No less to worse it both than our Rome,\n",
            "For what says your dear\n",
            "And will be married with him.\n",
            "\n",
            "PERDITA:\n",
            "Have you that your love thing I would command,\n",
            "And that Marcius Capitol; and, so much know\n",
            "That your honour should shall be put all to it.\n",
            "\n",
            "Second Servingman:\n",
            "I would the song could for our real of souls,\n",
            "He would not have at shame, where fairest for joy,\n",
            "For our common person of your son?\n",
            "\n",
            "First Servingman:\n",
            "T\n",
            "---------------\n",
            "\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Give you in the maid, our brother Ruies is the dishonour is done.\n",
            "\n",
            "LUCIO:\n",
            "But in this colour to have been him made him at our grace,\n",
            "within his purposers have compounded, his power\n",
            "to hurl your change to the sacred flatter.\n",
            "\n",
            "Provost:\n",
            "But it is true; and but on the cousin Juliet, I saw\n",
            "it will have a traitor in the death of her to you.\n",
            "\n",
            "POMPEY:\n",
            "Not speak to-morrow, she would be your honour's father.\n",
            "\n",
            "POMPEY:\n",
            "This is in the cork upon you with cut off a traitor sound.\n",
            "\n",
            "ISABELLA:\n",
            "Br\n",
            "---------------\n",
            "\n",
            "Which only have here, with following the babe,\n",
            "And so was written as every wolves of me;\n",
            "And eyes will appear fell as easily,\n",
            "And opposite that fits to vein the war.\n",
            "\n",
            "LEONTES:\n",
            "No, no;\n",
            "I would thou know the man.\n",
            "\n",
            "LEONTES:\n",
            "And what hast thou there?\n",
            "\n",
            "POLIXENES:\n",
            "Anon!\n",
            "\n",
            "CAPULET:\n",
            "We will not do hold thee.\n",
            "\n",
            "CAPULET:\n",
            "Who is the lamb?\n",
            "\n",
            "PAULINA:\n",
            "She will must not be born to the boy o' the\n",
            "better to the part; and there's good one with her words,\n",
            "Show the most officious foot. Camillo,\n",
            "What's the ground of y\n",
            "---------------\n",
            "\n",
            "Be entready without loss are courtiers of eighbour:\n",
            "I should tell your queen, so I am in harbour\n",
            "Before your time have an entreaty to her.\n",
            "\n",
            "LEONTES:\n",
            "True, by the hand: I will not stay.\n",
            "\n",
            "PAULINA:\n",
            "I do prove her.\n",
            "\n",
            "LEONTES:\n",
            "I have been so not so full of counsels, but that\n",
            "Have all the world wore on you.\n",
            "\n",
            "LEONTES:\n",
            "But in the lumb of all twenty! Art thou comest\n",
            "To come. Come, nurse, good comfort, services, my\n",
            "good letters, to the time to raise o' the bower;\n",
            "And haple a scarborries by your prisoner, i\n",
            "---------------\n",
            "\n",
            "\n",
            "CAPULET:\n",
            "Nay, be it little a man that thou that wouldst not be drunkart.\n",
            "\n",
            "CAPULET:\n",
            "\n",
            "POMPEY:\n",
            "A man, a right.\n",
            "\n",
            "CAPULET:\n",
            "Hie earner stands more pave up and livers of the merkets,\n",
            "Or that he will not lie on the one.\n",
            "\n",
            "CAPULET:\n",
            "So do you not revenge: come in.\n",
            "\n",
            "CAPULET:\n",
            "I must be not sport as to be known with a flower.\n",
            "\n",
            "CAPULET:\n",
            "A cousin, with mine honour wisdom to my lodge.\n",
            "\n",
            "CAPULET:\n",
            "Villain, that's not fall of my love, which, my mistruster have no grown:\n",
            "That is not was most strikely and far all his\n",
            "---------------\n",
            "\n",
            "My lord's death, and like the magfer of Lancaster;\n",
            "For who is a pipe of this princely royal liege,\n",
            "Catisfied to the adventure, lords, and withal,\n",
            "Yet obpose me stock in power.\n",
            "\n",
            "FLORIZEL:\n",
            "Go you speak not;\n",
            "For that I would think, if I do bring the chastise.\n",
            "And I had affect to see you to be a father\n",
            "Desert all these south and to frosten your true courses\n",
            "Are hut done. Let them bring their counsels\n",
            "Corrupt to see the people admiring.\n",
            "\n",
            "Lord:\n",
            "What, ho! what?\n",
            "\n",
            "Messenger:\n",
            "Thine, of any soon of this do\n",
            "---------------\n",
            "\n",
            "\n",
            "BUCKINGHAM:\n",
            "But, here's a lover. Come, Pompey, 'every with your house,\n",
            "Be here enough. The great York is not ever\n",
            "To be so fair was touch'd? Well, come, sir, sir, to our side,\n",
            "Nor she will do with you.\n",
            "\n",
            "GLOUCESTER:\n",
            "From you not shrive, how many heart with my brother!\n",
            "\n",
            "CATESBY:\n",
            "\n",
            "Ghost of MARGARET:\n",
            "I wot how.\n",
            "\n",
            "GLOUCESTER:\n",
            "It is the day that hath been it seen you,\n",
            "For now I am so unworth to but that embrace with\n",
            "Clarence or it?\n",
            "\n",
            "EXETER:\n",
            "I am colours yours as far hundred your sights,\n",
            "When you devis\n",
            "---------------\n",
            "\n",
            "Even up, my liege, noble lord, quoth with a story woman,\n",
            "Because I was for your mother.\n",
            "\n",
            "GLOUCESTER:\n",
            "Your sorrow, how yours, we have no little words.\n",
            "\n",
            "LADY ANNE:\n",
            "Well go, let me leave your good grace.\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "LADY ANNE:\n",
            "I cannot speak to my liege.\n",
            "\n",
            "GLOUCESTER:\n",
            "And have no other so dead,\n",
            "To relent the tempted. What has your lordship to mine own that war.\n",
            "\n",
            "GLOUCESTER:\n",
            "But why should a servant of the churchyard, which makes her brother?\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "LADY ANNE:\n",
            "Here's so your title what thou?\n",
            "---------------\n",
            "\n",
            "The doors and thread of mine eyes against the palace\n",
            "Persuade the desert kingdom'd the sea? but what?\n",
            "No one only good drum. Perhap will you be sure,\n",
            "You must race that a benefit of mine eye,\n",
            "That you environ'd the blood was will case your honour's face\n",
            "And think for you in your honour's loads: pray you,\n",
            "To the possession of the duke order,\n",
            "And so yours over in this must be purposed\n",
            "To prison! Do you e'er will have a tall'n the best\n",
            "Wise you of the best; and so yours. Go you to this,\n",
            "You do well\n",
            "---------------\n",
            "\n",
            "BUCKINGHAM:\n",
            "Ay. What than? what conscience?\n",
            "\n",
            "GLOUCESTER:\n",
            "How now, my lord! whut think'st thou? an honour?\n",
            "\n",
            "BUCKINGHAM:\n",
            "You tarry, not me, my lord.\n",
            "\n",
            "GLOUCESTER:\n",
            "Why, how now, come, my lord, I do a poison will be hated.\n",
            "\n",
            "GLOUCESTER:\n",
            "Say, why should I not seem to the wretch?\n",
            "You have done to the pursuimage. Ah, what thou now, threat'st!\n",
            "\n",
            "GLOUCESTER:\n",
            "Thing canst thou stop of this former that gave your honours\n",
            "That may be the senators.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Come, come, Clifford, Warwick, Warwick; I will no\n",
            "---------------\n"
          ]
        }
      ]
    }
  ]
}